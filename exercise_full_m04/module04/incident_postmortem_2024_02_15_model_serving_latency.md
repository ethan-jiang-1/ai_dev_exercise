# 事件复盘报告：2024-02-15 模型推理服务 P1 级延迟告警

*   **事件编号**: INC-20240215-003
*   **状态**: 已完成
*   **事件定级**: P1 (严重影响核心功能)
*   **发生时间**: 2024-02-15 10:35 UTC+8
*   **结束时间**: 2024-02-15 11:50 UTC+8
*   **持续时间**: 1 小时 15 分钟
*   **主要影响**: `NovaBrain 3.0` 平台部分核心客户（特别是金融行业客户）的实时文本分析 API 调用出现显著延迟（P99 延迟 > 5 秒），部分请求超时失败。
*   **涉及服务**: `model-inference-service` (模型推理服务集群 B), `api-gateway`, `model-registry`
*   **负责人**: 王工 (SRE 负责人)
*   **参与人员**: 李工 (模型推理服务Owner), 赵工 (平台运维), 孙工 (网络), 相关研发工程师

## 事件摘要

2024年2月15日上午10:35，监控系统触发模型推理服务集群 B (主要服务金融客户的高并发场景) 的 P99 延迟 P1 级告警。用户反馈部分实时文本分析请求响应缓慢或超时。经过紧急排查，发现原因是新部署的模型版本 (`text-classifier-v2.1`) 在处理特定类型长文本输入时，与 gRPC 连接池配置存在不兼容，导致连接资源耗尽，请求阻塞。通过紧急回滚模型版本至 `v2.0`，服务于 11:50 恢复正常。

## 事件时间线 (UTC+8)

*   **10:35**: 监控系统发出 P1 告警：`model-inference-service` 集群 B P99 延迟 > 5000ms。
*   **10:37**: SRE 团队收到告警，王工确认为 P1 事件，启动应急响应流程。
*   **10:40**: 初步排查：`api-gateway` 显示大量指向 `model-inference-service` 集群 B 的请求pending，集群 B Pod CPU/Memory 使用率正常，但 gRPC Active Connections 指标异常飙升。
*   **10:45**: 李工 (推理服务Owner) 加入排查，怀疑与上午 10:00 部署的新模型 `text-classifier-v2.1` 有关。
*   **10:55**: 定位问题：通过分析服务日志和 gRPC 连接指标，发现大量连接处于 `WAITING` 状态，且新建连接请求被阻塞。进一步分析新模型代码，发现其在处理超过 4096 token 的输入时，会进入一个资源密集型的预处理步骤，且未正确释放 gRPC 相关资源句柄。
*   **11:10**: 决策：制定回滚计划，将集群 B 的模型版本回滚至 `text-classifier-v2.0`。
*   **11:15**: 执行回滚操作：通过 `model-registry` 服务触发模型版本切换，并滚动更新 `model-inference-service` 集群 B 的 Pods。
*   **11:40**: 监控指标恢复：gRPC Active Connections 指标下降，P99 延迟恢复到 200ms 以下。
*   **11:50**: 确认服务完全恢复：API 调用成功率 100%，延迟正常。事件关闭。

## 根本原因分析 (RCA)

1.  **直接原因**: 新模型版本 `text-classifier-v2.1` 在处理特定长文本输入时存在缺陷，未能正确管理和释放 gRPC 连接资源，导致连接池耗尽。
2.  **促成原因 1**: 模型部署前的性能测试和压力测试未能覆盖到这种极端长文本输入场景。
3.  **促成原因 2**: `model-inference-service` 对 gRPC 连接池的配置（如最大连接数、超时时间）对于这种异常场景不够健壮，缺乏有效的熔断或快速失败机制。
4.  **促成原因 3**: 缺乏针对 gRPC 连接池耗尽的细粒度监控和告警。

## 解决与恢复

*   **紧急措施**: 将 `model-inference-service` 集群 B 的模型版本回滚至稳定的 `text-classifier-v2.0`。
*   **恢复验证**: 通过监控 API 网关和 `model-inference-service` 的延迟、错误率、资源使用率等指标，确认服务恢复正常。

## 行动项 (Action Items)

| # | 行动项                                                     | 负责人 | 状态   | 截止日期   |
|---|------------------------------------------------------------|--------|--------|------------|
| 1 | 修复 `text-classifier-v2.1` 模型处理长文本时的资源管理 Bug     | 李工   | 进行中 | 2024-02-20 |
| 2 | 增强模型部署前的测试用例，增加极端长文本和边界条件压力测试     | 测试团队 | 未开始 | 2024-02-29 |
| 3 | 审查并优化 `model-inference-service` 的 gRPC 客户端/服务端配置 | 王工   | 未开始 | 2024-02-28 |
| 4 | 增加 gRPC 连接池状态（活跃、空闲、等待）的细粒度监控和告警     | 赵工   | 未开始 | 2024-03-05 |
| 5 | 评估引入 gRPC 请求级别的超时和熔断机制的可能性               | 李工/王工| 未开始 | 2024-03-15 |

## 经验教训 (Lessons Learned)

*   **模型测试需覆盖边界场景**: 即使是看似微小的模型更新，也需要进行全面的压力测试，特别是针对可能触发资源瓶颈的边界输入。
*   **基础设施需有韧性**: 服务配置（如连接池）需要考虑异常情况，具备一定的容错能力。
*   **监控需深入细节**: 除了宏观的服务指标，还需要关注底层资源（如连接池）的细粒度监控，以便更快地定位问题。
*   **回滚预案的重要性**: 快速可靠的回滚机制是线上稳定的重要保障。 