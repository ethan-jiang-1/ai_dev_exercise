# NovaBrain 3.0 部署策略 V1.0

*   **项目**: NovaBrain 3.0
*   **文档版本**: 1.0
*   **状态**: 最终草案
*   **日期**: 2024-01-25
*   **负责人**: 王工 (SRE 负责人), 张工 (架构师)
*   **目标**: 定义 NovaBrain 3.0 平台服务和通过平台部署的 AI 模型的标准化部署流程、环境和策略，确保部署的可靠性、可重复性和安全性。

## 1. 概述

本策略涵盖两个主要部署场景：
1.  **平台服务部署**: 指 NovaBrain 3.0 自身微服务（如 API Gateway, Low-Code Engine, Model Registry, Inference Service 等）的更新和部署。
2.  **模型部署**: 指用户通过 NovaBrain 平台（主要是 Model Registry 和 Low-Code Pipeline）将训练好的 AI 模型部署到推理环境的过程。

目标是实现自动化、低风险的部署流程，并具备快速回滚和故障恢复能力。

## 2. 部署环境

我们定义以下标准部署环境：

*   **Development (开发环境)**: 
    *   用途: 开发人员本地或共享的开发测试环境，用于功能开发和单元测试。
    *   部署方式: 手动部署或通过开发分支的 CI 触发。
    *   数据: 模拟数据或脱敏数据子集。
*   **Staging (预发布环境)**: 
    *   用途: 模拟生产环境，用于集成测试、UAT 测试、性能测试。
    *   部署方式: 通过主干分支合并触发的 CI/CD 自动部署。
    *   数据: 接近生产数据的脱敏数据集或生产数据只读副本（严格控制）。
    *   配置: 与生产环境尽可能一致。
*   **Canary (金丝雀环境)**: 
    *   用途: 生产环境的一部分，用于小流量验证新版本的功能和性能。
    *   部署方式: 生产部署流程的第一步，手动触发或特定 CI/CD Job 触发。
    *   数据: 生产数据。
    *   流量: 通常承载 < 5% 的生产流量。
*   **Production (生产环境)**: 
    *   用途: 面向最终用户的正式服务环境。
    *   部署方式: 经过 Canary 验证后，逐步全量部署。
    *   数据: 生产数据。

## 3. 平台服务部署策略

*   **技术栈**: Kubernetes (K8s), Docker, Helm, Jenkins/GitLab CI (CI/CD)
*   **CI/CD 流程**: 
    1.  开发者提交代码到 Git 仓库。
    2.  **CI (持续集成)**: 触发自动化构建 (Docker 镜像)、单元测试、代码扫描 (SAST)。
    3.  **CD (持续部署) - Staging**: CI 成功后，自动将新版本部署到 Staging 环境。
    4.  **自动化测试**: 在 Staging 环境运行集成测试、API 测试、基础性能测试。
    5.  **手动验证/UAT**: 相关人员在 Staging 环境进行手动验证或 UAT。
    6.  **CD - Canary**: 手动触发或特定 Tag 触发，将新版本部署到生产 K8s 集群的 Canary Pods。
    7.  **Canary 验证**: 监控 Canary 环境的错误率、延迟、资源使用率等指标，持续一小时或更长时间。必要时进行小范围用户功能验证。
    8.  **CD - Production Rollout**: Canary 验证通过后，逐步将流量切换到新版本 Pods（如滚动更新），同时缩减旧版本 Pods。
*   **部署策略**: 
    *   **无状态服务**: 优先采用 **滚动更新 (Rolling Update)**。
    *   **有状态服务/数据库变更**: 需要更谨慎的策略，可能涉及停机维护窗口、数据迁移脚本，或采用 **蓝绿部署 (Blue/Green Deployment)** （需要额外资源）。
*   **回滚机制**: 
    *   CI/CD 工具提供一键回滚到上一稳定版本的功能 (基于 Helm 或 K8s deployment history)。
    *   制定详细的回滚预案，包括触发条件、执行步骤、验证方法。

## 4. 模型部署策略 (通过 NovaBrain 平台)

*   **触发**: 用户在模型注册表中将模型版本标记为 `Production` 状态（需要相应权限，见 TN-SEC-002 漏洞修复建议），或通过 Low-Code Pipeline 中的部署节点触发。
*   **流程**: 
    1.  **触发部署**: 用户操作触发模型部署请求。
    2.  **模型拉取**: 模型推理服务 (Inference Service) 监控模型注册表状态变更或接收部署指令，从注册表获取指定模型版本的元数据和模型文件下载路径。
    3.  **模型加载**: 推理服务实例从对象存储下载模型文件，并加载到内存或指定设备 (CPU/GPU)。
    4.  **服务发现更新**: 推理服务将新加载的模型信息注册到服务发现机制（如 K8s Service + Endpoint Slices, 或专门的模型路由层）。
    5.  **(可选) Canary 部署**: 对于关键模型或重大更新，可以先将模型部署到一个独立的 Canary 推理服务实例组，导入少量流量进行验证，验证通过后再部署到主生产实例组。
    6.  **健康检查**: 新模型加载后，推理服务应提供健康检查端点，验证模型是否成功加载并能响应基础请求。
*   **部署目标**: 模型通常部署到专用的 `model-inference-service` K8s 集群。
*   **模型版本切换**: 
    *   **滚动更新**: 逐步替换提供旧模型版本的 Pods/实例为提供新模型版本的 Pods/实例。
    *   **蓝绿部署**: 准备一组完整的提供新模型的实例，验证通过后将流量一次性切换过去（需要更多资源）。
*   **回滚**: 
    *   在模型注册表中将模型的 `Production` 状态指向上一个稳定版本。
    *   触发推理服务重新加载或回滚 K8s Deployment 至上一版本。

## 5. 部署后监控与验证

*   **关键指标**: 
    *   **平台服务**: API 延迟 (P99, P95, avg), 错误率 (4xx, 5xx), Pod CPU/内存使用率, K8s 事件。
    *   **模型推理**: 推理延迟, 推理请求 QPS, 模型加载成功/失败次数, GPU 使用率 (如适用)。
    *   **业务指标**: (根据具体应用定义) 如模型预测准确率漂移、业务转化率变化等。
*   **工具**: Prometheus, Grafana, ELK/Loki Stack (日志), Jaeger/Tempo (追踪)。
*   **告警**: 基于关键指标设置告警规则，及时发现部署引入的问题。
*   **验证**: 部署完成后，运行自动化冒烟测试，并进行手动核心功能验证。

## 6. 安全考虑

*   所有部署操作需要经过身份验证和授权。
*   CI/CD 流程中的密钥、密码等敏感信息需通过 Secrets Management 工具管理。
*   部署产物 (Docker 镜像) 需要进行漏洞扫描。
*   生产环境访问权限最小化。

## 7. 文档与演练

*   为每个服务的部署和回滚流程编写详细的操作手册 (Runbook)。
*   定期进行部署和回滚演练，确保流程有效性和团队熟练度。 